import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
from utils.model import get_model, load_model
import numpy as np
import io

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Ph√¢n lo·∫°i L·ªói S·∫£n Ph·∫©m ƒê√∫c",
    page_icon="üè≠",
    layout="wide",
)

# --- CSS T√πy ch·ªânh ---
st.markdown("""
<style>
    .st-emotion-cache-1y4p8pa {
        padding-top: 2rem;
    }
    .st-emotion-cache-1v0mbdj {
        max-width: 95%;
    }
    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E90FF;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-title {
        font-size: 1.5rem;
        color: #4682B4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .result-text {
        font-size: 1.8rem;
        font-weight: bold;
        text-align: center;
        padding: 1rem;
        border-radius: 10px;
    }
    .result-ok {
        color: #2E8B57;
        background-color: #D4EDDA;
    }
    .result-def {
        color: #A52A2A;
        background-color: #F8D7DA;
    }
</style>
""", unsafe_allow_html=True)


# --- H√†m x·ª≠ l√Ω ---
@st.cache_resource
def load_pytorch_model():

    model = get_model()
    try:
       
        model_path = 'final_model.pth'
        model = load_model(model, model_path)
        model.eval()
        return model
    except FileNotFoundError:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y t·ªáp 'final_model.pth'. Vui l√≤ng t·∫£i t·ªáp m√¥ h√¨nh v√† ƒë·∫∑t v√†o th∆∞ m·ª•c d·ª± √°n.")
        return None

def predict(model, image_data):
    """D·ª± ƒëo√°n ·∫£nh l√† OK hay L·ªói."""
    if model is None:
        return None, None

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.Grayscale(num_output_channels=3),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    image = Image.open(io.BytesIO(image_data)).convert("RGB")
    image_tensor = transform(image).unsqueeze(0).to(device)

    with torch.no_grad():
        outputs = model(image_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        confidence, predicted_idx = torch.max(probabilities, 1)
        predicted_class = predicted_idx.item()

    return predicted_class, confidence.item()

# --- Giao di·ªán ·ª©ng d·ª•ng ---

# Ti√™u ƒë·ªÅ
st.markdown("<h1 class='main-title'>üè≠ ·ª®ng d·ª•ng Ph√°t hi·ªán L·ªói S·∫£n ph·∫©m ƒê√∫c</h1>", unsafe_allow_html=True)
st.markdown("<p class='sub-title'>T·∫£i l√™n h√¨nh ·∫£nh s·∫£n ph·∫©m ƒë·ªÉ ki·ªÉm tra ch·∫•t l∆∞·ª£ng</p>", unsafe_allow_html=True)

# T·∫£i m√¥ h√¨nh
model = load_pytorch_model()

# C·ªôt ƒë·ªÉ hi·ªÉn th·ªã
col1, col2 = st.columns(2, gap="large")

with col1:
    st.header("üñºÔ∏è T·∫£i ·∫£nh l√™n")
    uploaded_files = st.file_uploader(
        "Ch·ªçn m·ªôt ·∫£nh s·∫£n ph·∫©m...",
        type=["jpg", "jpeg", "png"],
        accept_multiple_files=True  
    )

    if uploaded_files and model is not None:
        st.header("üí° K·∫øt qu·∫£ Ph√¢n lo·∫°i")

    # T·∫°o 3 c·ªôt ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ 
    cols = st.columns(3)
    col_index = 0

    # L·∫∑p qua t·ª´ng file ·∫£nh ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n
    for uploaded_file in uploaded_files:
        image_data = uploaded_file.getvalue()

        # ƒê·∫∑t k·∫øt qu·∫£ c·ªßa m·ªói ·∫£nh v√†o m·ªôt c·ªôt ri√™ng
        with cols[col_index]:
            st.image(image_data, caption=f"·∫¢nh: {uploaded_file.name}", width=True)

            # Ph√¢n lo·∫°i v√† hi·ªÉn th·ªã k·∫øt qu·∫£
            predicted_class, confidence = predict(model, image_data)
            # ... (code hi·ªÉn th·ªã k·∫øt qu·∫£ 'T·ªët' ho·∫∑c 'L·ªói') ...

        # Chuy·ªÉn sang c·ªôt ti·∫øp theo cho ·∫£nh k·∫ø ti·∫øp
        col_index = (col_index + 1) % len(cols)

with col2:
    st.header("üí° K·∫øt qu·∫£ Ph√¢n lo·∫°i")
    if uploaded_files is not None and model is not None:
        with st.spinner("ƒêang ph√¢n t√≠ch..."):
            predicted_class, confidence = predict(model, image_data)

            class_names = {0: 'L·ªói', 1: 'T·ªët'}
            result = class_names.get(predicted_class, "Kh√¥ng x√°c ƒë·ªãnh")
            confidence_percent = confidence * 100

            if result == 'T·ªët':
                st.markdown(f"<div class='result-text result-ok'>‚úîÔ∏è S·∫£n ph·∫©m T·ªêT</div>", unsafe_allow_html=True)
            else:
                st.markdown(f"<div class='result-text result-def'>‚ùå S·∫£n ph·∫©m c√≥ L·ªñI</div>", unsafe_allow_html=True)

            st.write("")
            st.metric(label="ƒê·ªô tin c·∫≠y", value=f"{confidence_percent:.2f}%")

            if result == 'L·ªói':
                 st.info("ƒê·ªÉ xem chi ti·∫øt v√† khoanh v√πng l·ªói, h√£y chuy·ªÉn qua trang **'üîç Ph√¢n T√≠ch Lo·∫°i L·ªói'**.")

    else:
        st.info("Vui l√≤ng t·∫£i ·∫£nh l√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n lo·∫°i.")

# H∆∞·ªõng d·∫´n
st.sidebar.title("üìñ H∆∞·ªõng d·∫´n")
st.sidebar.info(
    """
    1. **T·∫£i ·∫£nh l√™n:** Nh·∫•n v√†o 'Browse files' v√† ch·ªçn ·∫£nh s·∫£n ph·∫©m ƒë√∫c b·∫°n mu·ªën ki·ªÉm tra.
    2. **Xem k·∫øt qu·∫£:** M√¥ h√¨nh s·∫Ω t·ª± ƒë·ªông ph√¢n lo·∫°i ·∫£nh l√† 'T·ªët' ho·∫∑c 'L·ªói'.
    3. **Ph√¢n t√≠ch s√¢u:** N·∫øu s·∫£n ph·∫©m b·ªã l·ªói,  c√≥ th·ªÉ v√†o trang 'Ph√¢n T√≠ch Lo·∫°i L·ªói' t·ª´ thanh ƒëi·ªÅu h∆∞·ªõng b√™n c·∫°nh ƒë·ªÉ xem v·ªã tr√≠ v√† lo·∫°i l·ªói chi ti·∫øt.
    """
)
st.sidebar.title("V·ªÅ d·ª± √°n")
st.sidebar.success(
    """
    D·ª± √°n n√†y s·ª≠ d·ª•ng m√¥ h√¨nh h·ªçc s√¢u **EfficientNetV2-S** ƒë·ªÉ ph√¢n lo·∫°i s·∫£n ph·∫©m.
    ƒê·ªìng th·ªùi, √°p d·ª•ng c√°c thu·∫≠t to√°n x·ª≠ l√Ω ·∫£nh ƒë·ªÉ x√°c ƒë·ªãnh c√°c lo·∫°i l·ªói c·ª• th·ªÉ nh∆∞ 'N·ª©t', 'M·∫ª', 'L·ªó kh√≠'.
    """
)