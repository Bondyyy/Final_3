import streamlit as st
from PIL import Image
import torch
from torchvision import transforms
from utils.model import get_model, load_model
import numpy as np
import io

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Ph√¢n lo·∫°i L·ªói S·∫£n Ph·∫©m ƒê√∫c",
    page_icon="üè≠",
    layout="wide",
)

# --- CSS T√πy ch·ªânh (gi·ªØ nguy√™n) ---
st.markdown("""
<style>
    .st-emotion-cache-1y4p8pa {
        padding-top: 2rem;
    }
    .st-emotion-cache-1v0mbdj {
        max-width: 95%;
    }
    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1E90FF;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-title {
        font-size: 1.5rem;
        color: #4682B4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .result-text {
        font-size: 1.5rem; /* Gi·∫£m k√≠ch th∆∞·ªõc font ƒë·ªÉ v·ª´a v·∫∑n h∆°n */
        font-weight: bold;
        text-align: center;
        padding: 0.8rem;
        border-radius: 10px;
        margin-top: 10px;
    }
    .result-ok {
        color: #2E8B57;
        background-color: #D4EDDA;
    }
    .result-def {
        color: #A52A2A;
        background-color: #F8D7DA;
    }
</style>
""", unsafe_allow_html=True)


# --- H√†m x·ª≠ l√Ω (gi·ªØ nguy√™n) ---
@st.cache_resource
def load_pytorch_model():
    model = get_model()
    try:
        model_path = 'final_model.pth'
        model = load_model(model, model_path)
        model.eval()
        return model
    except FileNotFoundError:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y t·ªáp 'final_model.pth'. Vui l√≤ng t·∫£i t·ªáp m√¥ h√¨nh v√† ƒë·∫∑t v√†o th∆∞ m·ª•c d·ª± √°n.")
        return None

def predict(model, image_data):
    if model is None:
        return None, None
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.Grayscale(num_output_channels=3),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    image = Image.open(io.BytesIO(image_data)).convert("RGB")
    image_tensor = transform(image).unsqueeze(0).to(device)
    with torch.no_grad():
        outputs = model(image_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        confidence, predicted_idx = torch.max(probabilities, 1)
        predicted_class = predicted_idx.item()
    return predicted_class, confidence.item()

# --- Giao di·ªán ·ª©ng d·ª•ng ---

# Ti√™u ƒë·ªÅ
st.markdown("<h1 class='main-title'>üè≠ ·ª®ng d·ª•ng Ph√°t hi·ªán L·ªói S·∫£n ph·∫©m ƒê√∫c</h1>", unsafe_allow_html=True)
st.markdown("<p class='sub-title'>T·∫£i l√™n m·ªôt ho·∫∑c nhi·ªÅu h√¨nh ·∫£nh s·∫£n ph·∫©m ƒë·ªÉ ki·ªÉm tra ch·∫•t l∆∞·ª£ng</p>", unsafe_allow_html=True)

# T·∫£i m√¥ h√¨nh
model = load_pytorch_model()

# 1. Th√™m accept_multiple_files=True
uploaded_files = st.file_uploader(
    "Ch·ªçn m·ªôt ho·∫∑c nhi·ªÅu ·∫£nh s·∫£n ph·∫©m...",
    type=["jpg", "jpeg", "png"],
    accept_multiple_files=True # <<<< THAY ƒê·ªîI QUAN TR·ªåNG
)

if uploaded_files and model is not None:
    st.header("üí° K·∫øt qu·∫£ Ph√¢n lo·∫°i")
    
    # 2. T·∫°o c√°c c·ªôt ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ m·ªôt c√°ch g·ªçn g√†ng
    # B·∫°n c√≥ th·ªÉ thay ƒë·ªïi s·ªë 3 ƒë·ªÉ hi·ªÉn th·ªã nhi·ªÅu/√≠t ·∫£nh h∆°n tr√™n m·ªôt h√†ng
    cols = st.columns(3) 
    col_index = 0

    # 3. D√πng v√≤ng l·∫∑p ƒë·ªÉ x·ª≠ l√Ω t·ª´ng file
    for uploaded_file in uploaded_files:
        image_data = uploaded_file.getvalue()
        
        # S·ª≠ d·ª•ng with ƒë·ªÉ ƒë·∫∑t m·ªói k·∫øt qu·∫£ v√†o m·ªôt c·ªôt
        with cols[col_index]:
            st.image(image_data, caption=f"·∫¢nh: {uploaded_file.name}", use_container_width=True)
            
            with st.spinner(f"Ph√¢n t√≠ch {uploaded_file.name}..."):
                predicted_class, confidence = predict(model, image_data)

                class_names = {0: 'L·ªói', 1: 'T·ªët'}
                result = class_names.get(predicted_class, "Kh√¥ng x√°c ƒë·ªãnh")
                confidence_percent = confidence * 100

                if result == 'T·ªët':
                    st.markdown(f"<div class='result-text result-ok'>‚úîÔ∏è T·ªêT ({confidence_percent:.1f}%)</div>", unsafe_allow_html=True)
                else:
                    st.markdown(f"<div class='result-text result-def'>‚ùå L·ªñI ({confidence_percent:.1f}%)</div>", unsafe_allow_html=True)

        # Chuy·ªÉn sang c·ªôt ti·∫øp theo, n·∫øu h·∫øt h√†ng th√¨ t·∫°o h√†ng m·ªõi
        col_index = (col_index + 1) % len(cols)

elif not uploaded_files:
    st.info("Vui l√≤ng t·∫£i ·∫£nh l√™n ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n lo·∫°i.")

st.sidebar.title("üìñ H∆∞·ªõng d·∫´n")
st.sidebar.info(
    """
    1. **T·∫£i ·∫£nh l√™n:** Nh·∫•n v√†o 'Browse files' v√† ch·ªçn m·ªôt ho·∫∑c nhi·ªÅu ·∫£nh s·∫£n ph·∫©m.
    2. **Xem k·∫øt qu·∫£:** M√¥ h√¨nh s·∫Ω t·ª± ƒë·ªông ph√¢n lo·∫°i t·∫•t c·∫£ c√°c ·∫£nh ƒë√£ t·∫£i l√™n.
    3. **Ph√¢n t√≠ch s√¢u:** N·∫øu s·∫£n ph·∫©m b·ªã l·ªói, b·∫°n c√≥ th·ªÉ v√†o trang 'Ph√¢n T√≠ch Lo·∫°i L·ªói' ƒë·ªÉ xem chi ti·∫øt.
    """
)
st.sidebar.title("V·ªÅ d·ª± √°n")
st.sidebar.success(
    """
    D·ª± √°n n√†y s·ª≠ d·ª•ng m√¥ h√¨nh h·ªçc s√¢u **EfficientNetV2-S** ƒë·ªÉ ph√¢n lo·∫°i s·∫£n ph·∫©m.
    """
)